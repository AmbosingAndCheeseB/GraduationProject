# -*- coding: utf-8 -*-
"""last_test

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GLGuYgCypFigLoMze9apORCs2k7ZLRo_
"""

from google.colab import drive
drive.mount('/content/drive/')

!ls "/content/drive/My Drive/Jolp/"
!pip install pytorch-pretrained-bert pytorch-nlp

import argparse
import torch
from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler
from pytorch_pretrained_bert import BertTokenizer, BertConfig
from pytorch_pretrained_bert import BertAdam, BertForMaskedLM
import numpy as np
import re


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
n_gpu = torch.cuda.device_count()
torch.cuda.get_device_name(0)
'''
parser = argparse.ArgumentParser()

parser.add_argument('--problem', type = str, required=True)


args = parser.parse_args()
p_list = args.problem.split('/')
'''
args = "Mr. Uemura declined to  _  on rumors abouthow many medicines the drug manufacturerhad in development./ commenting/ commentary/ comment/ comments"

p_list = args.split('/')

def get_score(model, tokenizer, input_tensor, segment_tensor, masked_index, candidate):
  candidate_tokens = tokenizer.tokenize(candidate)
  candidate_ids = tokenizer.convert_tokens_to_ids(candidate_tokens)
  predictions = model(input_tensor, segment_tensor)
  print(predictions)
  print(predictions.size())
  predictions_candidates = predictions[0, masked_index, candidate_ids].mean()
  print(predictions[0, masked_index, candidate_ids])

  del input_tensor
  del segment_tensor

  return predictions_candidates.item()


try:
    problem = re.sub('\_+', ' [MASK] ', p_list[0])

    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)

    tokenized_texts = tokenizer.tokenize(problem)

    masked_idx = tokenized_texts.index("[MASK]")

    input_ids = tokenizer.convert_tokens_to_ids(tokenized_texts)

    segment_ids = [0] * len(tokenized_texts)

    problem_tensors = torch.tensor([input_ids]).to(device)
    segment_tensors = torch.tensor([segment_ids]).to(device)
    candidates = [p_list[1], p_list[2], p_list[3], p_list[4]]

    model = BertForMaskedLM.from_pretrained('bert-base-uncased')
    model.cuda()

    PATH = "/content/drive/My Drive/Jolp/param/epoch10.pt"

    checkpoint = torch.load(PATH)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()

    with torch.no_grad():
        logit = torch.tensor([get_score(model, tokenizer, problem_tensors , segment_tensors, masked_idx, candi) for candi in candidates])
        logit_idx = torch.argmax(logit).item()
        print(logit.data)
        print(candidates[logit_idx])

except Exception as ex:
    print(ex)

